{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a3a56a7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All required packages present.\n",
      "Generating small synthetic EEG dataset (fast demo).\n",
      "Generated 160 trials, 8 channels, 512 samples per trial.\n",
      "Saved synthetic dataset (wide CSV) to: /Users/stageacomeback/Desktop/output_small_eeg_demo/synthetic_signals_wide.csv\n",
      "Failed to save Excel file. Install 'openpyxl' or 'xlsxwriter' to enable Excel export. Error: No module named 'openpyxl'\n",
      "Computing band-power features (per trial) ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature extraction:   0%|          | 0/160 [00:00<?, ?it/s]/var/folders/6f/twg_bwys7xb6mgr86_05x41m0000gn/T/ipykernel_2801/1288220017.py:109: DeprecationWarning: `trapz` is deprecated. Use `trapezoid` instead, or one of the numerical integration functions in `scipy.integrate`.\n",
      "  total_power = np.trapz(ch_psd[total_idx], freqs[total_idx]) + 1e-12\n",
      "/var/folders/6f/twg_bwys7xb6mgr86_05x41m0000gn/T/ipykernel_2801/1288220017.py:112: DeprecationWarning: `trapz` is deprecated. Use `trapezoid` instead, or one of the numerical integration functions in `scipy.integrate`.\n",
      "  bp = np.trapz(ch_psd[idx], freqs[idx])\n",
      "Feature extraction: 100%|██████████| 160/160 [00:00<00:00, 1668.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature matrix X shape: (160, 40)\n",
      "Label distribution: {'Anxious': 40, 'Depressed': 40, 'Sad': 40, 'Fear': 40}\n",
      "\n",
      "Running LOSO multiclass evaluation (RandomForest)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8250\n",
      "Balanced Accuracy: 0.8250\n",
      "Macro ROC AUC (OVR): 0.9660\n",
      "\n",
      "Classification report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Anxious       0.74      0.70      0.72        40\n",
      "   Depressed       0.93      0.93      0.93        40\n",
      "         Sad       0.93      0.93      0.93        40\n",
      "        Fear       0.71      0.75      0.73        40\n",
      "\n",
      "    accuracy                           0.82       160\n",
      "   macro avg       0.83      0.82      0.82       160\n",
      "weighted avg       0.83      0.82      0.82       160\n",
      "\n",
      "Confusion matrix:\n",
      " [[28  0  0 12]\n",
      " [ 0 37  3  0]\n",
      " [ 0  3 37  0]\n",
      " [10  0  0 30]]\n",
      "Saved confusion matrix to: /Users/stageacomeback/Desktop/output_small_eeg_demo/confusion_matrix_loso.png\n",
      "\n",
      "Training RandomForest on the full feature set to obtain feature importances (approx).\n",
      "Top 20 features (name, importance):\n",
      "  theta_ch2             0.063483\n",
      "  theta_ch6             0.057592\n",
      "  theta_ch7             0.043826\n",
      "  alpha_ch5             0.040927\n",
      "  alpha_ch8             0.040107\n",
      "  theta_ch1             0.034554\n",
      "  theta_ch5             0.033735\n",
      "  gamma_ch5             0.033629\n",
      "  theta_ch3             0.032943\n",
      "  theta_ch8             0.031280\n",
      "  alpha_ch1             0.030847\n",
      "  theta_ch4             0.030105\n",
      "  gamma_ch3             0.029779\n",
      "  delta_ch7             0.026051\n",
      "  delta_ch5             0.025342\n",
      "  alpha_ch2             0.024473\n",
      "  gamma_ch2             0.024430\n",
      "  gamma_ch8             0.023861\n",
      "  beta_ch6              0.023700\n",
      "  gamma_ch6             0.022747\n",
      "Saved feature importances to: /Users/stageacomeback/Desktop/output_small_eeg_demo/feature_importances.png\n",
      "Saved trial-level predictions to: /Users/stageacomeback/Desktop/output_small_eeg_demo/trial_predictions.csv\n",
      "\n",
      "Done. Outputs are in: /Users/stageacomeback/Desktop/output_small_eeg_demo\n",
      "Reminder: synthetic labels are illustrative. For real data, provide a loader or dataset path.\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "Small EEG discrete-emotion demo (ready-to-paste)\n",
    "\n",
    "- Default: generates a tiny synthetic EEG dataset and maps trials to four discrete\n",
    "  emotion classes: 'Anxious', 'Depressed', 'Sad', 'Fear'.\n",
    "- Computes band-power features (delta/theta/alpha/beta/gamma) per channel.\n",
    "- Performs Leave-One-Subject-Out (LOSO) classification with RandomForest.\n",
    "- Prints metrics and saves confusion matrix + feature importances into ./output_small_eeg_demo\n",
    "\n",
    "Notes:\n",
    "- This is a small demo (seconds to a few minutes depending on CPU).\n",
    "- The \"Anxious/Depressed/Sad/Fear\" labels in the synthetic data are illustrative only.\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import subprocess\n",
    "import importlib\n",
    "import math\n",
    "from collections import OrderedDict\n",
    "\n",
    "# -------------------- Auto-install missing packages (optional) --------------------\n",
    "_REQ_PKGS = {\n",
    "    'numpy': 'numpy',\n",
    "    'scipy': 'scipy',\n",
    "    'sklearn': 'scikit-learn',\n",
    "    'matplotlib': 'matplotlib',\n",
    "    'pandas': 'pandas',\n",
    "    'tqdm': 'tqdm',\n",
    "    'requests': 'requests',\n",
    "    'seaborn': 'seaborn',\n",
    "}\n",
    "\n",
    "def ensure_packages(pack_map):\n",
    "    missing = []\n",
    "    for import_name, pip_name in pack_map.items():\n",
    "        try:\n",
    "            importlib.import_module(import_name)\n",
    "        except Exception:\n",
    "            missing.append(pip_name)\n",
    "    if missing:\n",
    "        print(\"Installing missing packages via pip:\", missing)\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\"] + missing)\n",
    "    else:\n",
    "        print(\"All required packages present.\")\n",
    "\n",
    "# Uncomment the next line to auto-install if you want; otherwise install packages yourself.\n",
    "try:\n",
    "    ensure_packages(_REQ_PKGS)\n",
    "except Exception as e:\n",
    "    print(\"Package auto-install failed or skipped. Make sure required packages are installed.\")\n",
    "    print(\"Error:\", e)\n",
    "\n",
    "# -------------------- Imports --------------------\n",
    "import numpy as np\n",
    "from scipy.signal import welch\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler, label_binarize\n",
    "from sklearn.model_selection import LeaveOneGroupOut\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, balanced_accuracy_score, confusion_matrix, classification_report,\n",
    "    roc_auc_score\n",
    ")\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "\n",
    "# -------------------- Configuration --------------------\n",
    "RANDOM_STATE = 42\n",
    "np.random.seed(RANDOM_STATE)\n",
    "\n",
    "# Small dataset parameters (fast)\n",
    "N_SUBJECTS = 8                  # small number of synthetic subjects\n",
    "TRIALS_PER_SUBJECT = 20         # trials per subject => total 160 trials\n",
    "N_CHANNELS = 8                  # small channel count (keeps feature vector small)\n",
    "FS = 128                        # sampling rate (Hz)\n",
    "DURATION_SEC = 4.0              # seconds per trial (short for speed)\n",
    "N_SAMPLES = int(FS * DURATION_SEC)\n",
    "EMOTION_CATS = ['Anxious', 'Depressed', 'Sad', 'Fear']  # discrete emotion labels\n",
    "OUTPUT_DIR = os.path.abspath(\"./output_small_eeg_demo\")\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# Frequency bands used for features\n",
    "BANDS = OrderedDict([\n",
    "    (\"delta\", (1, 4)),\n",
    "    (\"theta\", (4, 8)),\n",
    "    (\"alpha\", (8, 13)),\n",
    "    (\"beta\",  (13, 30)),\n",
    "    (\"gamma\", (30, 45)),\n",
    "])\n",
    "\n",
    "# Welch parameters (ensure nperseg <= n_samples)\n",
    "DEFAULT_NPERSEG = min(256, N_SAMPLES)\n",
    "\n",
    "# -------------------- Utility: bandpower features --------------------\n",
    "def compute_bandpower_features(eeg_epoch, fs=FS, bands=BANDS, nperseg=DEFAULT_NPERSEG):\n",
    "    \"\"\"\n",
    "    eeg_epoch: ndarray (n_channels, n_samples)\n",
    "    returns: 1D array: for each channel and each band -> log(relative band power)\n",
    "    \"\"\"\n",
    "    freqs, psd = welch(eeg_epoch, fs=fs, nperseg=nperseg, axis=1)\n",
    "    n_channels = eeg_epoch.shape[0]\n",
    "    feats = []\n",
    "    total_idx = np.logical_and(freqs >= 1, freqs <= 45)\n",
    "    for ch in range(n_channels):\n",
    "        ch_psd = psd[ch, :]\n",
    "        total_power = np.trapz(ch_psd[total_idx], freqs[total_idx]) + 1e-12\n",
    "        for (low, high) in bands.values():\n",
    "            idx = np.logical_and(freqs >= low, freqs <= high)\n",
    "            bp = np.trapz(ch_psd[idx], freqs[idx])\n",
    "            feats.append(math.log((bp / total_power) + 1e-12))\n",
    "    return np.array(feats, dtype=float)\n",
    "\n",
    "# -------------------- Synthetic EEG data generator (small) --------------------\n",
    "def generate_synthetic_eeg(n_subjects=N_SUBJECTS,\n",
    "                           trials_per_subject=TRIALS_PER_SUBJECT,\n",
    "                           n_channels=N_CHANNELS,\n",
    "                           fs=FS, duration=DURATION_SEC,\n",
    "                           classes=EMOTION_CATS, random_state=RANDOM_STATE):\n",
    "    \"\"\"\n",
    "    Produce a small synthetic EEG dataset (time-series) and corresponding labels/groups.\n",
    "    Returns:\n",
    "      signals: ndarray (n_trials, n_channels, n_samples)\n",
    "      labels: list[str] length n_trials\n",
    "      groups: ndarray subject indices length n_trials\n",
    "    The synthetic signals are constructed by summing band-limited sine components with\n",
    "    class-specific band amplitude multipliers and simple channel topographies.\n",
    "    \"\"\"\n",
    "    rng = np.random.RandomState(random_state)\n",
    "    n_samples = int(fs * duration)\n",
    "    n_trials = n_subjects * trials_per_subject\n",
    "    signals = np.zeros((n_trials, n_channels, n_samples), dtype=float)\n",
    "    labels = []\n",
    "    groups = np.zeros(n_trials, dtype=int)\n",
    "\n",
    "    # Balanced label assignment\n",
    "    labels_cycle = []\n",
    "    n_classes = len(classes)\n",
    "    # create a balanced shuffled label list\n",
    "    base = classes * ( (n_trials // n_classes) + 1 )\n",
    "    labels_cycle = base[:n_trials]\n",
    "    rng.shuffle(labels_cycle)\n",
    "\n",
    "    # class-specific band multipliers (heuristic / illustrative)\n",
    "    class_band_multipliers = {\n",
    "        'Anxious':  {'delta':0.9,'theta':1.0,'alpha':0.9,'beta':1.6,'gamma':1.5},\n",
    "        'Depressed':{'delta':1.0,'theta':1.4,'alpha':0.6,'beta':0.8,'gamma':0.7},\n",
    "        'Sad':      {'delta':1.1,'theta':1.2,'alpha':0.8,'beta':0.9,'gamma':0.8},\n",
    "        'Fear':     {'delta':0.9,'theta':1.1,'alpha':0.8,'beta':1.7,'gamma':1.6},\n",
    "    }\n",
    "\n",
    "    # small channel topography: frontal channels (0..2) get boosted for high-arousal classes\n",
    "    channel_topography = np.ones(n_channels)\n",
    "    for ch in range(n_channels):\n",
    "        if ch <= 2:\n",
    "            channel_topography[ch] = 1.15\n",
    "        elif 3 <= ch <= 4:\n",
    "            channel_topography[ch] = 1.05\n",
    "        else:\n",
    "            channel_topography[ch] = 0.95\n",
    "\n",
    "    t = np.arange(n_samples) / fs\n",
    "\n",
    "    for i in range(n_trials):\n",
    "        cls = labels_cycle[i]\n",
    "        subj = i // trials_per_subject\n",
    "        labels.append(cls)\n",
    "        groups[i] = subj\n",
    "\n",
    "        # For each channel, sum a few sinusoids inside each band with amplitudes per class\n",
    "        for ch in range(n_channels):\n",
    "            sig = np.zeros(n_samples, dtype=float)\n",
    "            topo = channel_topography[ch]\n",
    "            for band, (low, high) in BANDS.items():\n",
    "                # choose 1-2 components per band\n",
    "                n_comps = rng.choice([1, 2])\n",
    "                for _c in range(n_comps):\n",
    "                    freq = rng.uniform(low, high)\n",
    "                    phase = rng.uniform(0, 2*np.pi)\n",
    "                    # base amplitude small; class multipliers shape the spectrum\n",
    "                    base_amp = 1.0\n",
    "                    class_mul = class_band_multipliers.get(cls, {}).get(band, 1.0)\n",
    "                    amp = base_amp * class_mul * topo * (1.0 + 0.15 * rng.randn())\n",
    "                    sig += amp * np.sin(2 * np.pi * freq * t + phase)\n",
    "            # add Gaussian noise (subject + trial variability)\n",
    "            noise_level = 0.5 * (1.0 + 0.2 * rng.randn())\n",
    "            sig += noise_level * rng.randn(n_samples)\n",
    "            signals[i, ch, :] = sig\n",
    "\n",
    "    return signals, labels, groups\n",
    "\n",
    "# -------------------- LOSO evaluation (multiclass) --------------------\n",
    "def loso_multiclass_evaluate(X, y, groups, class_names, classifier_type='rf', random_state=RANDOM_STATE):\n",
    "    \"\"\"\n",
    "    Perform Leave-One-Subject-Out multiclass evaluation.\n",
    "    Returns a result dict with predictions, probs, metrics, confusion matrix, and last classifier.\n",
    "    \"\"\"\n",
    "    logo = LeaveOneGroupOut()\n",
    "    n_samples = X.shape[0]\n",
    "    n_classes = len(class_names)\n",
    "    preds = np.zeros(n_samples, dtype=int)\n",
    "    probs = np.zeros((n_samples, n_classes), dtype=float)\n",
    "\n",
    "    last_clf = None\n",
    "    for fold_i, (train_idx, test_idx) in enumerate(logo.split(X, y, groups)):\n",
    "        # scale based only on training data\n",
    "        scaler = StandardScaler().fit(X[train_idx])\n",
    "        Xtr = scaler.transform(X[train_idx])\n",
    "        Xte = scaler.transform(X[test_idx])\n",
    "\n",
    "        if classifier_type == 'rf':\n",
    "            clf = RandomForestClassifier(n_estimators=200, n_jobs=-1, random_state=random_state)\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported classifier_type, only 'rf' implemented in demo.\")\n",
    "\n",
    "        clf.fit(Xtr, y[train_idx])\n",
    "        preds[test_idx] = clf.predict(Xte)\n",
    "        if hasattr(clf, \"predict_proba\"):\n",
    "            probs[test_idx] = clf.predict_proba(Xte)\n",
    "        else:\n",
    "            # fallback: one-hot from decision_function (not expected here)\n",
    "            probs[test_idx] = 0.0\n",
    "            probs[test_idx, preds[test_idx]] = 1.0\n",
    "\n",
    "        last_clf = clf\n",
    "\n",
    "    # Metrics\n",
    "    acc = accuracy_score(y, preds)\n",
    "    bacc = balanced_accuracy_score(y, preds)\n",
    "    cls_report = classification_report(y, preds, target_names=class_names, zero_division=0)\n",
    "    cm = confusion_matrix(y, preds)\n",
    "\n",
    "    # multiclass ROC AUC (one-vs-rest macro)\n",
    "    try:\n",
    "        y_bin = label_binarize(y, classes=list(range(n_classes)))\n",
    "        auc_macro = roc_auc_score(y_bin, probs, average='macro', multi_class='ovr')\n",
    "    except Exception:\n",
    "        auc_macro = float('nan')\n",
    "\n",
    "    return {\n",
    "        'preds': preds,\n",
    "        'probs': probs,\n",
    "        'acc': acc,\n",
    "        'bacc': bacc,\n",
    "        'auc_macro': auc_macro,\n",
    "        'class_report': cls_report,\n",
    "        'cm': cm,\n",
    "        'clf': last_clf\n",
    "    }\n",
    "\n",
    "# -------------------- Small plotting helpers --------------------\n",
    "def plot_confusion_matrix(cm, class_names, outpath):\n",
    "    plt.figure(figsize=(6,5))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.title('Confusion matrix (LOSO)')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(outpath)\n",
    "    plt.close()\n",
    "\n",
    "def plot_feature_importances(importances, feature_names, outpath, topk=20):\n",
    "    idx_sorted = np.argsort(importances)[::-1]\n",
    "    top_idx = idx_sorted[:topk]\n",
    "    top_names = [feature_names[i] for i in top_idx][::-1]\n",
    "    top_vals = importances[top_idx][::-1]\n",
    "    plt.figure(figsize=(7, max(3, 0.25*len(top_names))))\n",
    "    y_pos = np.arange(len(top_names))\n",
    "    plt.barh(y_pos, top_vals, align='center')\n",
    "    plt.yticks(y_pos, top_names)\n",
    "    plt.xlabel(\"Importance\")\n",
    "    plt.title(\"Top feature importances (RF)\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(outpath)\n",
    "    plt.close()\n",
    "\n",
    "# -------------------- Main pipeline --------------------\n",
    "def main(use_real_dataset=False, real_dataset_path=None):\n",
    "    \"\"\"\n",
    "    If use_real_dataset=True and real_dataset_path is provided, the script will try to load it.\n",
    "    Otherwise the script uses the synthetic small dataset.\n",
    "    \"\"\"\n",
    "    # 1) Load or generate dataset\n",
    "    if use_real_dataset and real_dataset_path is not None:\n",
    "        # Placeholder: user-supplied loader could be implemented here.\n",
    "        raise NotImplementedError(\"Real dataset loading is not implemented in this demo. \"\n",
    "                                  \"Please supply a preprocessed feature matrix or request a custom loader.\")\n",
    "    else:\n",
    "        print(\"Generating small synthetic EEG dataset (fast demo).\")\n",
    "        signals, labels_str, groups = generate_synthetic_eeg()\n",
    "        n_trials = signals.shape[0]\n",
    "        print(f\"Generated {n_trials} trials, {signals.shape[1]} channels, {signals.shape[2]} samples per trial.\")\n",
    "\n",
    "        # Save raw synthetic dataset to CSV/Excel for review (wide format: one trial per row)\n",
    "        try:\n",
    "            n_trials, n_channels, n_samples = signals.shape\n",
    "            # Column names: trial, subject, label, then ch1_s0 ... chN_sM\n",
    "            col_names = ['trial', 'subject', 'label']\n",
    "            for ch in range(n_channels):\n",
    "                for s in range(n_samples):\n",
    "                    col_names.append(f\"ch{ch+1}_s{s}\")\n",
    "            data_rows = []\n",
    "            for i in range(n_trials):\n",
    "                row = [i, int(groups[i]), labels_str[i]]\n",
    "                # Flatten channel-major: ch0 samples then ch1 samples ...\n",
    "                row.extend(signals[i].reshape(-1).tolist())\n",
    "                data_rows.append(row)\n",
    "            df_signals = pd.DataFrame(data_rows, columns=col_names)\n",
    "            csv_signals_path = os.path.join(OUTPUT_DIR, \"synthetic_signals_wide.csv\")\n",
    "            df_signals.to_csv(csv_signals_path, index=False)\n",
    "            print(\"Saved synthetic dataset (wide CSV) to:\", csv_signals_path)\n",
    "\n",
    "            excel_signals_path = os.path.join(OUTPUT_DIR, \"synthetic_signals_wide.xlsx\")\n",
    "            try:\n",
    "                df_signals.to_excel(excel_signals_path, index=False)\n",
    "                print(\"Saved synthetic dataset (Excel) to:\", excel_signals_path)\n",
    "            except Exception as e:\n",
    "                print(\"Failed to save Excel file. Install 'openpyxl' or 'xlsxwriter' to enable Excel export. Error:\", e)\n",
    "        except Exception as e:\n",
    "            print(\"Failed to save synthetic dataset to CSV/Excel:\", e)\n",
    "\n",
    "        # Compute features\n",
    "        X_list = []\n",
    "        print(\"Computing band-power features (per trial) ...\")\n",
    "        for i in tqdm(range(n_trials), desc=\"Feature extraction\"):\n",
    "            eeg_epoch = signals[i]  # shape (n_channels, n_samples)\n",
    "            feats = compute_bandpower_features(eeg_epoch)\n",
    "            X_list.append(feats)\n",
    "        X = np.vstack(X_list)\n",
    "        # label encoding (int)\n",
    "        class_to_idx = {c:i for i,c in enumerate(EMOTION_CATS)}\n",
    "        y = np.array([class_to_idx[c] for c in labels_str], dtype=int)\n",
    "        groups = np.array(groups, dtype=int)\n",
    "\n",
    "    print(\"Feature matrix X shape:\", X.shape)\n",
    "    print(\"Label distribution:\", {EMOTION_CATS[i]: int(np.sum(y==i)) for i in range(len(EMOTION_CATS))})\n",
    "    # Feature names\n",
    "    feature_names = []\n",
    "    for ch in range(signals.shape[1]):\n",
    "        for band in BANDS.keys():\n",
    "            feature_names.append(f\"{band}_ch{ch+1}\")\n",
    "\n",
    "    # 2) LOSO evaluation\n",
    "    print(\"\\nRunning LOSO multiclass evaluation (RandomForest)...\")\n",
    "    results = loso_multiclass_evaluate(X, y, groups, EMOTION_CATS, classifier_type='rf')\n",
    "    print(f\"Accuracy: {results['acc']:.4f}\")\n",
    "    print(f\"Balanced Accuracy: {results['bacc']:.4f}\")\n",
    "    print(f\"Macro ROC AUC (OVR): {results['auc_macro']:.4f}\")\n",
    "    print(\"\\nClassification report:\\n\")\n",
    "    print(results['class_report'])\n",
    "    print(\"Confusion matrix:\\n\", results['cm'])\n",
    "\n",
    "    # Save confusion matrix plot\n",
    "    cm_path = os.path.join(OUTPUT_DIR, \"confusion_matrix_loso.png\")\n",
    "    plot_confusion_matrix(results['cm'], EMOTION_CATS, cm_path)\n",
    "    print(\"Saved confusion matrix to:\", cm_path)\n",
    "\n",
    "    # 3) Train RF on full dataset to get feature importances (approximate)\n",
    "    print(\"\\nTraining RandomForest on the full feature set to obtain feature importances (approx).\")\n",
    "    scaler_full = StandardScaler().fit(X)\n",
    "    X_full = scaler_full.transform(X)\n",
    "    rf_full = RandomForestClassifier(n_estimators=500, n_jobs=-1, random_state=RANDOM_STATE)\n",
    "    rf_full.fit(X_full, y)\n",
    "    importances = rf_full.feature_importances_\n",
    "    topk = min(20, len(importances))\n",
    "    top_idx = np.argsort(importances)[::-1][:topk]\n",
    "    print(f\"Top {topk} features (name, importance):\")\n",
    "    for i in top_idx:\n",
    "        print(f\"  {feature_names[i]:20s}  {importances[i]:.6f}\")\n",
    "\n",
    "    # Save feature importances plot\n",
    "    fi_path = os.path.join(OUTPUT_DIR, \"feature_importances.png\")\n",
    "    plot_feature_importances(importances, feature_names, fi_path, topk=topk)\n",
    "    print(\"Saved feature importances to:\", fi_path)\n",
    "\n",
    "    # 4) Save simple CSV summary\n",
    "    df = pd.DataFrame({\n",
    "        'subject': groups,\n",
    "        'label': [EMOTION_CATS[int(lbl)] for lbl in y],\n",
    "        'pred': [EMOTION_CATS[int(p)] for p in results['preds']]\n",
    "    })\n",
    "    csv_path = os.path.join(OUTPUT_DIR, \"trial_predictions.csv\")\n",
    "    df.to_csv(csv_path, index=False)\n",
    "    print(\"Saved trial-level predictions to:\", csv_path)\n",
    "\n",
    "    print(\"\\nDone. Outputs are in:\", OUTPUT_DIR)\n",
    "    print(\"Reminder: synthetic labels are illustrative. For real data, provide a loader or dataset path.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # By default, run the synthetic demo. If you want me to wire a small real dataset\n",
    "    # (e.g., DREAMER) into this pipeline, say so and I'll add the downloader/loader.\n",
    "    main(use_real_dataset=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
